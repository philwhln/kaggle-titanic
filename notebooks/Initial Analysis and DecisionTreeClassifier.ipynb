{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview thoughts\n",
    "Of the 891 passengers...\n",
    "* All have non-null info on Survived, Pclass, Sex, SibSp, Parch, Ticket, Fare.\n",
    "* Embarked is only missing 2, so might be worth just dropping those two, if Embarked is useful. Otherwise, dropping the Embarked feature.\n",
    "* Cabin is mostly nulls, so probably not worth using if only available 22% of the time.\n",
    "* Age is probably useful, but 20% are missing that field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents thoughts\n",
    "* **PClass**. (Ticket Class). Preferential treatment for higher class? Nice simple field to work with.  \n",
    "* **Name**. Unique. Probably is not useful unless there's some bias in race or class that can be derived from the names. That would involve some deep analysis and probably an external dataset to find name embeddings. Although just the length of the name may indicate something.\n",
    "* **SibSp** (Siblings + Spouses onboard). Safety in numbers? Would be interesting to correlate this with Name and see if there's any likely holes here.\n",
    "* **Parch** (Parents + Children onboard). Very similar to SibSp, although from the movies \"women and children first\" would indicate this carriers more weight for adult females than adults males. Not that useful for children, since we already know they are from their Age. It's also difficult to tell if the person is the parent or the child, as even an adult could be the child. More broadly useful for safety in numbers?\n",
    "* **Ticket**. Unique? Probably not usual, if unique, unless it indicates more information on where, when, or how the ticket was purchased that would compliment Class. Or if it gives information that relates to the Cabin.\n",
    "* **Fare**. Relates to the Class. Variability might indicate more granular levels in Class or some preferencial treatment at the time of purchase.\n",
    "* **Embarked** (Port of Embarkation). Again, this may add colour to the background of person that may have played a part. For instance, would someone with a certain accent be treated differently? Would someone from a different region/climate be more apt to surviving?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "died = (df.Survived == 0.).sum()\n",
    "survived = (df.Survived == 1.).sum()\n",
    "percent_died = 100. * died / (died + survived)\n",
    "print(f'{died} died ({percent_died:0.1f}%). {survived} survived ({100. - percent_died:0.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Pclass.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Groups\n",
    "Let's just use Fibonacci for now. Looks about right. Life expectancy of white men and women around 1912 was around 50-55 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [0., 1., 2., 3., 5., 8., 13., 21., 34., 55., 89.]\n",
    "age_group_labels = [f'Under {b}' for b in age_bins[1:]]\n",
    "df['AgeGroup'] = pd.cut(df.Age, bins=age_bins, labels=age_group_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AgeGroup'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_survived = df['AgeGroup'].where(df['Survived'] == 1.).value_counts()\n",
    "age_group_died = df['AgeGroup'].where(df['Survived'] == 0.).value_counts()\n",
    "age_group_survived_df = pd.DataFrame({\n",
    "    'Survived': age_group_survived,\n",
    "    'Died': age_group_died,\n",
    "}, index=df['AgeGroup'].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_survived_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_survived_df.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_survived_df['DeathRate'] = 100. * age_group_survived_df['Died']\\\n",
    "    / (age_group_survived_df['Died'] + age_group_survived_df['Survived'])\n",
    "age_group_survived_df['DeathRate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Death rate by age thoughts\n",
    "* Under 8 years old is generally better for survival. In practically it probably on the survival of the parent and the parent probably gets better treatment if they they have children.\n",
    "* Older than 55 has highest rate of mortality. This is inline with life-expectancy at the time.\n",
    "\n",
    "_Note: I played with the age groups a little and didn't find any particular benefit to using non-fibonacci buckets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass (Ticket Class) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# some plots derived from https://seaborn.pydata.org/generated/seaborn.countplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='Pclass', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Pclass\", hue=\"Survived\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Huge bias for dying in 3rd Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictability = 0.\n",
    "for c in [1, 2, 3]:\n",
    "    in_class = df['Survived'].where(df['Pclass'] == c)\n",
    "    died = in_class.where(df['Survived'] == 0.).count()\n",
    "    survived = in_class.where(df['Survived'] == 1.).count()\n",
    "    class_death_rate = died / (died + survived)\n",
    "    prob_of_class = in_class.count() / len(df)\n",
    "    if c == 1:\n",
    "        # Let's always guess that 1st Class survives.\n",
    "        # We'll be right most of the time.\n",
    "        class_predictability = 1. - class_death_rate\n",
    "    elif c == 2:\n",
    "        # Let's always guess that 2nd Class dies.\n",
    "        # We'll be right slightly more than we're wrong.\n",
    "        class_predictability = class_death_rate\n",
    "    elif c == 3:\n",
    "        # Let's always guess that 3rd Class dies.\n",
    "        # We'll be right most of the time.\n",
    "        class_predictability = class_death_rate\n",
    "        \n",
    "    predictability += class_predictability * prob_of_class\n",
    "    print((c, died, survived, class_death_rate, prob_of_class, class_predictability))\n",
    "\n",
    "print(f'Predictability of death based on class data alone is {100. * predictability:0.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the most basic model that always predicted you'd die in 3rd Class would be 75.76% accurate for just that class. Overall we could use this data to get 67.9% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model - DecisionTreeClassifier\n",
    "It would be good to start cleaning the data and get basic model going.\n",
    "Let's train on the following fields for now...\n",
    "* PClass. One-hot encode.\n",
    "* Sex. Convert to Male (0. or 1.)\n",
    "* Age. Convert NaNs to average age. Bucket as Fibonacci (see above) and one-hot encode.\n",
    "* SibSp. Normalize to range 0. to 1. Possible test data has higher number, which could skew things.\n",
    "* Parch. Normalize to range 0. to 1. Possible test data has higher number, which could skew things.\n",
    "* Fare. Normalize to range 0. to 1. Better to bucket this?\n",
    "\n",
    "Obviously output is Survival, which will be a binary classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def prep_input_data(titanic_df):\n",
    "    unchanged_x_cols = ['Pclass', 'SibSp', 'Parch']\n",
    "\n",
    "    df_clean = titanic_df[unchanged_x_cols].copy()\n",
    "    df_clean['Male'] = 0.\n",
    "    df_clean.loc[titanic_df['Sex'] == 'male', 'Male'] = 1.\n",
    "    \n",
    "    x_cols = unchanged_x_cols + ['Male']\n",
    "\n",
    "    return df_clean, x_cols\n",
    "\n",
    "\n",
    "def prep_training_data(titanic_df):\n",
    "    df_clean, x_cols = prep_input_data(titanic_df)\n",
    "\n",
    "    y_col = ['Survived']\n",
    "    df_clean[y_col] = titanic_df[y_col]\n",
    "    \n",
    "    # shuffle\n",
    "    df_clean = df_clean.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train_len = int(0.8 * len(df_clean))\n",
    "    \n",
    "    df_train = df_clean.head(train_len)\n",
    "    df_val = df_clean.tail(len(df_clean) - train_len)\n",
    "    \n",
    "    return df_train, df_val, x_cols, y_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "df_train, df_val, x_cols, y_col = prep_training_data(df)\n",
    "\n",
    "df_train.info()\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(df_train[x_cols], df_train[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(df_train[x_cols])\n",
    "\n",
    "train_accuracy = metrics.accuracy_score(df_train[y_col], train_predictions)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = clf.predict(df_val[x_cols])\n",
    "\n",
    "val_accuracy = metrics.accuracy_score(df_val[y_col], val_predictions)\n",
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')\n",
    "df_test.info()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_input, _ = prep_input_data(df_test)\n",
    "\n",
    "df_test_input.info()\n",
    "df_test_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = clf.predict(df_test_input)\n",
    "\n",
    "df_submission = pd.DataFrame({\n",
    "    'PassengerId': df_test['PassengerId'],\n",
    "    'Survived': test_predictions,\n",
    "})\n",
    "\n",
    "df_submission.to_csv('../output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission 1\n",
    "\n",
    "This submission got **0.77272**, but isn't too bad considering how basic it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
